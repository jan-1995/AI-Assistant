

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>langchain.chat_models.openai.ChatOpenAI &mdash; ðŸ¦œðŸ”— LangChain 0.0.247</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/chat_models/langchain.chat_models.openai.ChatOpenAI.html" />

  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/autodoc_pydantic.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" type="text/css" />
  <link rel="stylesheet" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
  <link rel="stylesheet" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <link rel="stylesheet" href="/_/static/css/badge_only.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 

<!-- RTD Extra Head -->

<link rel="stylesheet" href="/_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": false, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/docs/api_reference", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "chat_models/langchain.chat_models.openai.ChatOpenAI", "programming_language": "words", "project": "langchain", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "scikit-learn-modern", "user_analytics_code": "", "version": "latest"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="/_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
<body>





<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../api_reference.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../experimental_api_reference.html">Experimental</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://python.langchain.com/">Python Docs</a>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="langchain.chat_models.mlflow_ai_gateway.ChatParams.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="langchain.chat_models.mlflow_ai_gateway.ChatParams">Prev</a><a href="../api_reference.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="langchain API Reference">Up</a>
            <a href="langchain.chat_models.promptlayer_openai.PromptLayerChatOpenAI.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="langchain.chat_models.promptlayer_openai.PromptLayerChatOpenAI">Next</a>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>LangChain 0.0.247</strong><br/>
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain.chat_models.openai</span></code>.ChatOpenAI</a></li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="langchain-chat-models-openai-chatopenai">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain.chat_models.openai</span></code>.ChatOpenAI<a class="headerlink" href="#langchain-chat-models-openai-chatopenai" title="Permalink to this headline">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">langchain.chat_models.openai.</span></span><span class="sig-name descname"><span class="pre">ChatOpenAI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackHandler.html#langchain.callbacks.base.BaseCallbackHandler" title="langchain.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_manager</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gpt-3.5-turbo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_organization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_proxy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">request_timeout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">streaming</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tiktoken_model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/langchain/chat_models/openai.html#ChatOpenAI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="langchain.chat_models.base.BaseChatModel.html#langchain.chat_models.base.BaseChatModel" title="langchain.chat_models.base.BaseChatModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseChatModel</span></code></a></p>
<p>Wrapper around OpenAI Chat large language models.</p>
<p>To use, you should have the <code class="docutils literal notranslate"><span class="pre">openai</span></code> python package installed, and the
environment variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> set with your API key.</p>
<p>Any parameters that are valid to be passed to the openai.create call can be passed
in, even if not explicitly saved on this class.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="n">openai</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p>
<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.cache">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cache</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.cache" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Whether to cache the response.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.callback_manager">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">callback_manager</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.callback_manager" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Callback manager to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.callbacks">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">callbacks</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callbacks</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.callbacks" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Callbacks to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.max_retries">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_retries</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.max_retries" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Maximum number of retries to make when generating.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.max_tokens">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.max_tokens" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Maximum number of tokens to generate.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.metadata">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.metadata" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Metadata to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.model_kwargs">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.model_kwargs" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Holds any model parameters valid for <cite>create</cite> call not explicitly specified.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.model_name">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gpt-3.5-turbo'</span></em><em class="property"> <span class="pre">(alias</span> <span class="pre">'model')</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.model_name" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Model name to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.n">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.n" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Number of chat completions to generate for each prompt.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.openai_api_base">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_api_base</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.openai_api_base" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.openai_api_key">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_api_key</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.openai_api_key" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Base URL path for API requests,
leave blank if not using a proxy or service emulator.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.openai_organization">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_organization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.openai_organization" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.openai_proxy">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">openai_proxy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.openai_proxy" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.request_timeout">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">request_timeout</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.request_timeout" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Timeout for requests to OpenAI completion API. Default is 600 seconds.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.streaming">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">streaming</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.streaming" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Whether to stream the results or not.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.tags">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tags</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.tags" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Tags to add to the run trace.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.temperature">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.7</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.temperature" title="Permalink to this definition">Â¶</a></dt>
<dd><p>What sampling temperature to use.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.tiktoken_model_name">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tiktoken_model_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.tiktoken_model_name" title="Permalink to this definition">Â¶</a></dt>
<dd><p>The model name to pass to tiktoken when using this class.
Tiktoken is used to count the number of tokens in documents to constrain
them to be under a certain limit. By default, when set to None, this will
be the same as the embedding model name. However, there are some cases
where you may want to use this Embedding class with a model name not
supported by tiktoken. This can include when using Azure embeddings or
when using one of the many model providers that expose an OpenAI-like
API but with different models. In those cases, in order to avoid erroring
when tiktoken is called, you can specify a model name to use here.</p>
</dd></dl>

<dl class="py attribute pydantic_field">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.verbose">
<em class="property"><span class="pre">param</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"> <span class="pre">[Optional]</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.verbose" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Whether to print out response text.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackHandler.html#langchain.callbacks.base.BaseCallbackHandler" title="langchain.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.__call__" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Call self as a function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.agenerate">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackHandler.html#langchain.callbacks.base.BaseCallbackHandler" title="langchain.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.output.LLMResult.html#langchain.schema.output.LLMResult" title="langchain.schema.output.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.agenerate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Top Level call</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.agenerate_prompt">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">agenerate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.prompt.PromptValue.html#langchain.schema.prompt.PromptValue" title="langchain.schema.prompt.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackHandler.html#langchain.callbacks.base.BaseCallbackHandler" title="langchain.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.output.LLMResult.html#langchain.schema.output.LLMResult" title="langchain.schema.output.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.agenerate_prompt" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Asynchronously pass a sequence of prompts and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> â€“ List of PromptValues. A PromptValue is an object that can be
converted to match the format of any language model (string for pure
text generation models and BaseMessages for chat models).</p></li>
<li><p><strong>stop</strong> â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> â€“ Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.ainvoke">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ainvoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.prompt.PromptValue.html#langchain.schema.prompt.PromptValue" title="langchain.schema.prompt.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.runnable.RunnableConfig.html#langchain.schema.runnable.RunnableConfig" title="langchain.schema.runnable.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessageChunk.html#langchain.schema.messages.BaseMessageChunk" title="langchain.schema.messages.BaseMessageChunk"><span class="pre">BaseMessageChunk</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.ainvoke" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.apredict">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.apredict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Asynchronously pass a string to the model and return a string prediction.</p>
<dl class="simple">
<dt>Use this method when calling pure text generation models and only the top</dt><dd><p>candidate generation is needed.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> â€“ String input to pass to the model.</p></li>
<li><p><strong>stop</strong> â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>**kwargs</strong> â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Top model prediction as a string.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.apredict_messages">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apredict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.apredict_messages" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Asynchronously pass messages to the model and return a message prediction.</p>
<dl class="simple">
<dt>Use this method when calling chat models and only the top</dt><dd><p>candidate generation is needed.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> â€“ A sequence of chat messages corresponding to a single model input.</p></li>
<li><p><strong>stop</strong> â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>**kwargs</strong> â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Top model prediction as a message.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.astream">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">astream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.prompt.PromptValue.html#langchain.schema.prompt.PromptValue" title="langchain.schema.prompt.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.runnable.RunnableConfig.html#langchain.schema.runnable.RunnableConfig" title="langchain.schema.runnable.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AsyncIterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessageChunk.html#langchain.schema.messages.BaseMessageChunk" title="langchain.schema.messages.BaseMessageChunk"><span class="pre">BaseMessageChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.astream" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method pydantic_validator">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.build_extra">
<em class="property"><span class="pre">validator</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">build_extra</span></span><em class="autodoc_pydantic_validator_arrow property">&#160; <span class="pre">Â»</span>&#160; </em><em class="xref py py-obj"><span class="pre">all</span> <span class="pre">fields</span></em><a class="reference internal" href="../_modules/langchain/chat_models/openai.html#ChatOpenAI.build_extra"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.build_extra" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build extra kwargs from additional params that were passed in.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.call_as_llm">
<span class="sig-name descname"><span class="pre">call_as_llm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.call_as_llm" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.completion_with_retry">
<span class="sig-name descname"><span class="pre">completion_with_retry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_manager</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.manager.CallbackManagerForLLMRun.html#langchain.callbacks.manager.CallbackManagerForLLMRun" title="langchain.callbacks.manager.CallbackManagerForLLMRun"><span class="pre">CallbackManagerForLLMRun</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="reference internal" href="../_modules/langchain/chat_models/openai.html#ChatOpenAI.completion_with_retry"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.completion_with_retry" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Use tenacity to retry the completion call.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.dict">
<span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a dictionary of the LLM.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackHandler.html#langchain.callbacks.base.BaseCallbackHandler" title="langchain.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.output.LLMResult.html#langchain.schema.output.LLMResult" title="langchain.schema.output.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.generate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Top Level call</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.generate_prompt">
<span class="sig-name descname"><span class="pre">generate_prompt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.prompt.PromptValue.html#langchain.schema.prompt.PromptValue" title="langchain.schema.prompt.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackHandler.html#langchain.callbacks.base.BaseCallbackHandler" title="langchain.callbacks.base.BaseCallbackHandler"><span class="pre">BaseCallbackHandler</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../callbacks/langchain.callbacks.base.BaseCallbackManager.html#langchain.callbacks.base.BaseCallbackManager" title="langchain.callbacks.base.BaseCallbackManager"><span class="pre">BaseCallbackManager</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.output.LLMResult.html#langchain.schema.output.LLMResult" title="langchain.schema.output.LLMResult"><span class="pre">LLMResult</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.generate_prompt" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Pass a sequence of prompts to the model and return model generations.</p>
<p>This method should make use of batched calls for models that expose a batched
API.</p>
<dl class="simple">
<dt>Use this method when you want to:</dt><dd><ol class="arabic simple">
<li><p>take advantage of batched calls,</p></li>
<li><p>need more output from the model than just the top generated value,</p></li>
<li><dl class="simple">
<dt>are building chains that are agnostic to the underlying language model</dt><dd><p>type (e.g., pure text completion models vs chat models).</p>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompts</strong> â€“ List of PromptValues. A PromptValue is an object that can be
converted to match the format of any language model (string for pure
text generation models and BaseMessages for chat models).</p></li>
<li><p><strong>stop</strong> â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>callbacks</strong> â€“ Callbacks to pass through. Used for executing additional
functionality, such as logging or streaming, throughout generation.</p></li>
<li><p><strong>**kwargs</strong> â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An LLMResult, which contains a list of candidate Generations for each input</dt><dd><p>prompt and additional model provider-specific output.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.get_num_tokens">
<span class="sig-name descname"><span class="pre">get_num_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.get_num_tokens" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the number of tokens present in the text.</p>
<p>Useful for checking if an input will fit in a modelâ€™s context window.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> â€“ The string input to tokenize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The integer number of tokens in the text.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.get_num_tokens_from_messages">
<span class="sig-name descname"><span class="pre">get_num_tokens_from_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../_modules/langchain/chat_models/openai.html#ChatOpenAI.get_num_tokens_from_messages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.get_num_tokens_from_messages" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Calculate num tokens for gpt-3.5-turbo and gpt-4 with tiktoken package.</p>
<p>Official documentation: <a class="reference external" href="https://github.com/openai/openai-cookbook/blob/">https://github.com/openai/openai-cookbook/blob/</a>
main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.get_token_ids">
<span class="sig-name descname"><span class="pre">get_token_ids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/langchain/chat_models/openai.html#ChatOpenAI.get_token_ids"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.get_token_ids" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get the tokens present in the text with tiktoken package.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.invoke">
<span class="sig-name descname"><span class="pre">invoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.prompt.PromptValue.html#langchain.schema.prompt.PromptValue" title="langchain.schema.prompt.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.runnable.RunnableConfig.html#langchain.schema.runnable.RunnableConfig" title="langchain.schema.runnable.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessageChunk.html#langchain.schema.messages.BaseMessageChunk" title="langchain.schema.messages.BaseMessageChunk"><span class="pre">BaseMessageChunk</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.invoke" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.predict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Pass a single string input to the model and return a string prediction.</p>
<blockquote>
<div><dl class="simple">
<dt>Use this method when passing in raw text. If you want to pass in specific</dt><dd><p>types of chat messages, use predict_messages.</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> â€“ String input to pass to the model.</p></li>
<li><p><strong>stop</strong> â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>**kwargs</strong> â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Top model prediction as a string.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.predict_messages">
<span class="sig-name descname"><span class="pre">predict_messages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.predict_messages" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Pass a message sequence to the model and return a message prediction.</p>
<dl class="simple">
<dt>Use this method when passing in chat messages. If you want to pass in raw text,</dt><dd><p>use predict.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> â€“ A sequence of chat messages corresponding to a single model input.</p></li>
<li><p><strong>stop</strong> â€“ Stop words to use when generating. Model output is cut off at the
first occurrence of any of these substrings.</p></li>
<li><p><strong>**kwargs</strong> â€“ Arbitrary additional keyword arguments. These are usually passed
to the model provider API call.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Top model prediction as a message.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method pydantic_validator">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.raise_deprecation">
<em class="property"><span class="pre">validator</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">raise_deprecation</span></span><em class="autodoc_pydantic_validator_arrow property">&#160; <span class="pre">Â»</span>&#160; </em><em class="xref py py-obj"><span class="pre">all</span> <span class="pre">fields</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.raise_deprecation" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Raise deprecation warning if callback_manager is used.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.stream">
<span class="sig-name descname"><span class="pre">stream</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.prompt.PromptValue.html#langchain.schema.prompt.PromptValue" title="langchain.schema.prompt.PromptValue"><span class="pre">PromptValue</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessage.html#langchain.schema.messages.BaseMessage" title="langchain.schema.messages.BaseMessage"><span class="pre">BaseMessage</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.runnable.RunnableConfig.html#langchain.schema.runnable.RunnableConfig" title="langchain.schema.runnable.RunnableConfig"><span class="pre">RunnableConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../schema/langchain.schema.messages.BaseMessageChunk.html#langchain.schema.messages.BaseMessageChunk" title="langchain.schema.messages.BaseMessageChunk"><span class="pre">BaseMessageChunk</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.stream" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.to_json">
<span class="sig-name descname"><span class="pre">to_json</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../load/langchain.load.serializable.SerializedConstructor.html#langchain.load.serializable.SerializedConstructor" title="langchain.load.serializable.SerializedConstructor"><span class="pre">SerializedConstructor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../load/langchain.load.serializable.SerializedNotImplemented.html#langchain.load.serializable.SerializedNotImplemented" title="langchain.load.serializable.SerializedNotImplemented"><span class="pre">SerializedNotImplemented</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.to_json" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.to_json_not_implemented">
<span class="sig-name descname"><span class="pre">to_json_not_implemented</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../load/langchain.load.serializable.SerializedNotImplemented.html#langchain.load.serializable.SerializedNotImplemented" title="langchain.load.serializable.SerializedNotImplemented"><span class="pre">SerializedNotImplemented</span></a></span></span><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.to_json_not_implemented" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method pydantic_validator">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.validate_environment">
<em class="property"><span class="pre">validator</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_environment</span></span><em class="autodoc_pydantic_validator_arrow property">&#160; <span class="pre">Â»</span>&#160; </em><em class="xref py py-obj"><span class="pre">all</span> <span class="pre">fields</span></em><a class="reference internal" href="../_modules/langchain/chat_models/openai.html#ChatOpenAI.validate_environment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.validate_environment" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Validate that api key and python package exists in environment.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.lc_attributes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lc_attributes</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.lc_attributes" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a list of attribute names that should be included in the
serialized kwargs. These attributes must be accepted by the
constructor.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.lc_namespace">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lc_namespace</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.lc_namespace" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return the namespace of the langchain object.
eg. [â€œlangchainâ€, â€œllmsâ€, â€œopenaiâ€]</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.lc_secrets">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lc_secrets</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.lc_secrets" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a map of constructor argument names to secret ids.
eg. {â€œopenai_api_keyâ€: â€œOPENAI_API_KEYâ€}</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.lc_serializable">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lc_serializable</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.lc_serializable" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return whether or not the class is serializable.</p>
</dd></dl>

<dl class="py class pydantic_config">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.Config">
<em class="property"><span class="pre">model</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Config</span></span><a class="reference internal" href="../_modules/langchain/chat_models/openai.html#ChatOpenAI.Config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.Config" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Configuration for this pydantic object.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="langchain.chat_models.openai.ChatOpenAI.Config.allow_population_by_field_name">
<span class="sig-name descname"><span class="pre">allow_population_by_field_name</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#langchain.chat_models.openai.ChatOpenAI.Config.allow_population_by_field_name" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

</dd></dl>

<h1>Examples using ChatOpenAI<a class="headerlink" href="#langchain-chat-models-openai-chatopenai" title="Permalink to this headline">Â¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/wikipedia">Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/retrievers/arxiv">Arxiv</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/chatgpt_plugins">ChatGPT Plugins</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/human_tools">Human as a tool</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/arxiv">ArXiv API Tool</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/metaphor_search">Metaphor Search</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/tools/bash">Shell Tool</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/memory/dynamodb_chat_message_history">Dynamodb Chat Message History</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/openai">OpenAI</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/context">Context</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/callbacks/promptlayer">PromptLayer</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/cnosdb">CnosDB</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/flyte">Flyte</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/arthur_tracking">Arthur</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/csv">CSV Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/document_comparison_toolkit">Document Comparison</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/python">Python Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/powerbi">PowerBI Dataset Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/sql_database">SQL Database Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/github">Github Toolkit</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/spark_sql">Spark SQL Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/pandas">Pandas Dataframe Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/toolkits/multion">Multion Toolkit</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_transformers/openai_metadata_tagger">OpenAI Functions Metadata Tagger</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_loaders/youtube_audio">Loading documents from a YouTube url</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/integrations/document_loaders/figma">Figma</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/debugging">Debugging</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/langsmith/walkthrough">LangSmith Walkthrough</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/evaluation/examples/qa_generation">QA Generation</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/evaluation/examples/comparisons">Comparing Chain Outputs</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/evaluation/trajectory/trajectory_eval">Agent Trajectory</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/evaluation/trajectory/custom">Custom Trajectory Evaluator</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/guides/evaluation/string/qa">QA Correctness</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/tagging">Tagging</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/autonomous_agents/autogpt">AutoGPT</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/autonomous_agents/marathon_times">!pip install bs4</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/document-context-aware-QA">Context aware text splitting and QA / Chat</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/index">QA over Documents</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/semantic-search-over-chat">Question answering over a group chat messages using Activeloopâ€™s DeepLake</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/how_to/document-context-aware-QA">Perform context-aware text splitting</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/how_to/qa_citations">Cite sources</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/how_to/flare">Retrieve as you generate with FLARE</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/integrations/openai_functions_retrieval_qa">Structure answers with OpenAI functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/question_answering/integrations/semantic-search-over-chat">QA using Activeloopâ€™s DeepLake</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/elasticsearch_database">Elasticsearch database</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/tabular/sql_query">SQL Query</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/neptune_cypher_qa">Neptune Open Cypher QA Chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/graph_nebula_qa">NebulaGraphQAChain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/graph_kuzu_qa">KuzuQAChain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/graph_hugegraph_qa">HugeGraph QA Chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/graph_sparql_qa">GraphSparqlQAChain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/graph_arangodb_qa">ArangoDB QA chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/graph_cypher_qa">Graph DB QA chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/code/twitter-the-algorithm-analysis-deeplake">Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Activeloopâ€™s Deep Lake</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/code/code-analysis-deeplake">Use LangChain, GPT and Activeloopâ€™s Deep Lake to work with code base</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agents/wikibase_agent">Wikibase Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agents/sales_agent_with_context">SalesGPT - Your Context-Aware AI Sales Assistant With Knowledge Base</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/camel_role_playing">CAMEL Role-Playing Autonomous Cooperative Agents</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/extraction/openai_extraction">Extraction with OpenAI Functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/petting_zoo">Multi-Agent Simulated Environment: Petting Zoo</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/multiagent_bidding">Multi-agent decentralized speaker selection</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/multiagent_authoritarian">Multi-agent authoritarian speaker selection</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/characters">Generative Agents in LangChain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/two_player_dnd">Two-Player Dungeons &amp; Dragons</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/multi_player_dnd">Multi-Player Dungeons &amp; Dragons</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/gymnasium">Simulated Environment: Gymnasium</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/use_cases/agent_simulations/two_agent_debate_tools">Agent Debates with Tools</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever">MultiQueryRetriever</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/data_connection/retrievers/web_research">WebResearchRetriever</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/memory/adding_memory">How to add Memory to an LLMChain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/callbacks/custom_callbacks">Custom callback handlers</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/callbacks/async_callbacks">Async callbacks</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/tools/custom_tools">Defining Custom Tools</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/tools/tools_as_openai_functions">Tools as OpenAI Functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/agent_types/openai_multi_functions_agent">OpenAI Multi Functions Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/handle_parsing_errors">Handle parsing errors</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/agent_iter">Running Agent as an Iterator</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/add_memory_openai_functions">Add Memory to OpenAI Functions Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/custom-functions-with-openai-functions-agent">Custom functions with OpenAI Functions Agent</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/agents/how_to/use_toolkits_with_openai_functions">Use ToolKits with OpenAI Functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/retry">Retry parser</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/output_parsers/pydantic">Pydantic (JSON) parser</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/prompts_pipelining">Prompt Pipelining</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store">Connecting to a Feature Store</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/how_to/custom_chain">Custom chain</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/popular/openai_functions">Using OpenAI functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/extraction">Extraction</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/openai_functions_retrieval_qa">Retrieval QA using OpenAI functions</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/qa_citations">Question-Answering Citations</a></p></li>
<li><p><a class="reference external" href="https://python.langchain.com/docs/modules/chains/additional/flare">FLARE</a></p></li>
</ul>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2023, Harrison Chase.
          Last updated on Jul 29, 2023.
          <a href="../_sources/chat_models/langchain.chat_models.openai.ChatOpenAI.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>
<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">Â¶</a>');
	});
});

</script>
    
</body>
</html>