

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>langchain.cache &mdash; ðŸ¦œðŸ”— LangChain 0.0.247</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/_modules/langchain/cache.html" />

  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/autodoc_pydantic.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <link rel="stylesheet" href="/_/static/css/badge_only.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 

<!-- RTD Extra Head -->

<link rel="stylesheet" href="/_/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="application/json" id="READTHEDOCS_DATA">{"ad_free": false, "api_host": "https://readthedocs.org", "builder": "sphinx", "canonical_url": null, "docroot": "/docs/api_reference", "features": {"docsearch_disabled": false}, "global_analytics_code": "UA-17997319-1", "language": "en", "page": "_modules/langchain/cache", "programming_language": "words", "project": "langchain", "proxied_api_host": "/_", "source_suffix": ".rst", "subprojects": {}, "theme": "scikit-learn-modern", "user_analytics_code": "", "version": "latest"}</script>

<!--
Using this variable directly instead of using `JSON.parse` is deprecated.
The READTHEDOCS_DATA global variable will be removed in the future.
-->
<script type="text/javascript">
READTHEDOCS_DATA = JSON.parse(document.getElementById('READTHEDOCS_DATA').innerHTML);
</script>

<script type="text/javascript" src="/_/static/javascript/readthedocs-analytics.js" async="async"></script>

<!-- end RTD <extrahead> -->
</head>
<body>





<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../api_reference.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../experimental_api_reference.html">Experimental</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://python.langchain.com/">Python Docs</a>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Prev</a><a href="../index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Module code">Up</a>
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Next</a>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>LangChain 0.0.247</strong><br/>
          </p>
        </div>
            <div class="sk-sidebar-toc">
              
            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <h1>Source code for langchain.cache</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Beta Feature: base interface for cache.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Sequence</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">cast</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">Column</span><span class="p">,</span> <span class="n">Integer</span><span class="p">,</span> <span class="n">String</span><span class="p">,</span> <span class="n">create_engine</span><span class="p">,</span> <span class="n">select</span>
<span class="kn">from</span> <span class="nn">sqlalchemy.engine.base</span> <span class="kn">import</span> <span class="n">Engine</span>
<span class="kn">from</span> <span class="nn">sqlalchemy.orm</span> <span class="kn">import</span> <span class="n">Session</span>

<span class="kn">from</span> <span class="nn">langchain.utils</span> <span class="kn">import</span> <span class="n">get_from_env</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sqlalchemy.orm</span> <span class="kn">import</span> <span class="n">declarative_base</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sqlalchemy.ext.declarative</span> <span class="kn">import</span> <span class="n">declarative_base</span>

<span class="kn">from</span> <span class="nn">langchain.embeddings.base</span> <span class="kn">import</span> <span class="n">Embeddings</span>
<span class="kn">from</span> <span class="nn">langchain.load.dump</span> <span class="kn">import</span> <span class="n">dumps</span>
<span class="kn">from</span> <span class="nn">langchain.load.load</span> <span class="kn">import</span> <span class="n">loads</span>
<span class="kn">from</span> <span class="nn">langchain.schema</span> <span class="kn">import</span> <span class="n">ChatGeneration</span><span class="p">,</span> <span class="n">Generation</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores.redis</span> <span class="kn">import</span> <span class="n">Redis</span> <span class="k">as</span> <span class="n">RedisVectorstore</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">momento</span>

<span class="n">RETURN_VAL_TYPE</span> <span class="o">=</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Generation</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_hash</span><span class="p">(</span><span class="n">_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Use a deterministic hashing approach.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">_input</span><span class="o">.</span><span class="n">encode</span><span class="p">())</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_dump_generations_to_json</span><span class="p">(</span><span class="n">generations</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dump generations to json.</span>

<span class="sd">    Args:</span>
<span class="sd">        generations (RETURN_VAL_TYPE): A list of language model generations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Json representing a list of generations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">([</span><span class="n">generation</span><span class="o">.</span><span class="n">dict</span><span class="p">()</span> <span class="k">for</span> <span class="n">generation</span> <span class="ow">in</span> <span class="n">generations</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_load_generations_from_json</span><span class="p">(</span><span class="n">generations_json</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load generations from json.</span>

<span class="sd">    Args:</span>
<span class="sd">        generations_json (str): A string of json representing a list of generations.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: Could not decode json string to list of generations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        RETURN_VAL_TYPE: A list of generations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">generations_json</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">Generation</span><span class="p">(</span><span class="o">**</span><span class="n">generation_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">generation_dict</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Could not decode json to list of generations: </span><span class="si">{</span><span class="n">generations_json</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>


<div class="viewcode-block" id="BaseCache"><a class="viewcode-back" href="../../cache/langchain.cache.BaseCache.html#langchain.cache.BaseCache">[docs]</a><span class="k">class</span> <span class="nc">BaseCache</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base interface for cache.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseCache.lookup"><a class="viewcode-back" href="../../cache/langchain.cache.BaseCache.html#langchain.cache.BaseCache.lookup">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RETURN_VAL_TYPE</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Look up based on prompt and llm_string.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BaseCache.update"><a class="viewcode-back" href="../../cache/langchain.cache.BaseCache.html#langchain.cache.BaseCache.update">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_val</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update cache based on prompt and llm_string.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="BaseCache.clear"><a class="viewcode-back" href="../../cache/langchain.cache.BaseCache.html#langchain.cache.BaseCache.clear">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear cache that can take additional keyword arguments.&quot;&quot;&quot;</span></div></div>


<div class="viewcode-block" id="InMemoryCache"><a class="viewcode-back" href="../../cache/langchain.cache.InMemoryCache.html#langchain.cache.InMemoryCache">[docs]</a><span class="k">class</span> <span class="nc">InMemoryCache</span><span class="p">(</span><span class="n">BaseCache</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache that stores things in memory.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize with empty cache.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="InMemoryCache.lookup"><a class="viewcode-back" href="../../cache/langchain.cache.InMemoryCache.html#langchain.cache.InMemoryCache.lookup">[docs]</a>    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RETURN_VAL_TYPE</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Look up based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span></div>

<div class="viewcode-block" id="InMemoryCache.update"><a class="viewcode-back" href="../../cache/langchain.cache.InMemoryCache.html#langchain.cache.InMemoryCache.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_val</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update cache based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">[(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">)]</span> <span class="o">=</span> <span class="n">return_val</span></div>

<div class="viewcode-block" id="InMemoryCache.clear"><a class="viewcode-back" href="../../cache/langchain.cache.InMemoryCache.html#langchain.cache.InMemoryCache.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear cache.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span> <span class="o">=</span> <span class="p">{}</span></div></div>


<span class="n">Base</span> <span class="o">=</span> <span class="n">declarative_base</span><span class="p">()</span>


<div class="viewcode-block" id="FullLLMCache"><a class="viewcode-back" href="../../cache/langchain.cache.FullLLMCache.html#langchain.cache.FullLLMCache">[docs]</a><span class="k">class</span> <span class="nc">FullLLMCache</span><span class="p">(</span><span class="n">Base</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SQLite table for full LLM Cache (all generations).&quot;&quot;&quot;</span>

    <span class="n">__tablename__</span> <span class="o">=</span> <span class="s2">&quot;full_llm_cache&quot;</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">String</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">String</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">Integer</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">Column</span><span class="p">(</span><span class="n">String</span><span class="p">)</span></div>


<div class="viewcode-block" id="SQLAlchemyCache"><a class="viewcode-back" href="../../cache/langchain.cache.SQLAlchemyCache.html#langchain.cache.SQLAlchemyCache">[docs]</a><span class="k">class</span> <span class="nc">SQLAlchemyCache</span><span class="p">(</span><span class="n">BaseCache</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache that uses SQAlchemy as a backend.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">engine</span><span class="p">:</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">cache_schema</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">FullLLMCache</span><span class="p">]</span> <span class="o">=</span> <span class="n">FullLLMCache</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize by creating all tables.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">engine</span> <span class="o">=</span> <span class="n">engine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span> <span class="o">=</span> <span class="n">cache_schema</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">create_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span>

<div class="viewcode-block" id="SQLAlchemyCache.lookup"><a class="viewcode-back" href="../../cache/langchain.cache.SQLAlchemyCache.html#langchain.cache.SQLAlchemyCache.lookup">[docs]</a>    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RETURN_VAL_TYPE</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Look up based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="n">stmt</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span><span class="o">.</span><span class="n">response</span><span class="p">)</span>
            <span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span><span class="o">.</span><span class="n">prompt</span> <span class="o">==</span> <span class="n">prompt</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span><span class="o">.</span><span class="n">llm</span> <span class="o">==</span> <span class="n">llm_string</span><span class="p">)</span>
            <span class="o">.</span><span class="n">order_by</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">Session</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">stmt</span><span class="p">)</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">rows</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">[</span><span class="n">loads</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">]</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;Retrieving a cache value that could not be deserialized &quot;</span>
                        <span class="s2">&quot;properly. This is likely due to the cache being in an &quot;</span>
                        <span class="s2">&quot;older format. Please recreate your cache to avoid this &quot;</span>
                        <span class="s2">&quot;error.&quot;</span>
                    <span class="p">)</span>
                    <span class="c1"># In a previous life we stored the raw text directly</span>
                    <span class="c1"># in the table, so assume it&#39;s in that format.</span>
                    <span class="k">return</span> <span class="p">[</span><span class="n">Generation</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">]</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="SQLAlchemyCache.update"><a class="viewcode-back" href="../../cache/langchain.cache.SQLAlchemyCache.html#langchain.cache.SQLAlchemyCache.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_val</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="n">items</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm_string</span><span class="p">,</span> <span class="n">response</span><span class="o">=</span><span class="n">dumps</span><span class="p">(</span><span class="n">gen</span><span class="p">),</span> <span class="n">idx</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">gen</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">return_val</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">with</span> <span class="n">Session</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">,</span> <span class="n">session</span><span class="o">.</span><span class="n">begin</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
                <span class="n">session</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">item</span><span class="p">)</span></div>

<div class="viewcode-block" id="SQLAlchemyCache.clear"><a class="viewcode-back" href="../../cache/langchain.cache.SQLAlchemyCache.html#langchain.cache.SQLAlchemyCache.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear cache.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">Session</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_schema</span><span class="p">)</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>
            <span class="n">session</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="SQLiteCache"><a class="viewcode-back" href="../../cache/langchain.cache.SQLiteCache.html#langchain.cache.SQLiteCache">[docs]</a><span class="k">class</span> <span class="nc">SQLiteCache</span><span class="p">(</span><span class="n">SQLAlchemyCache</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache that uses SQLite as a backend.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">database_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;.langchain.db&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize by creating the engine and all tables.&quot;&quot;&quot;</span>
        <span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;sqlite:///</span><span class="si">{</span><span class="n">database_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span></div>


<div class="viewcode-block" id="RedisCache"><a class="viewcode-back" href="../../cache/langchain.cache.RedisCache.html#langchain.cache.RedisCache">[docs]</a><span class="k">class</span> <span class="nc">RedisCache</span><span class="p">(</span><span class="n">BaseCache</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache that uses Redis as a backend.&quot;&quot;&quot;</span>

    <span class="c1"># TODO - implement a TTL policy in Redis</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">redis_</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize by passing in Redis instance.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">redis</span> <span class="kn">import</span> <span class="n">Redis</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Could not import redis python package. &quot;</span>
                <span class="s2">&quot;Please install it with `pip install redis`.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">redis_</span><span class="p">,</span> <span class="n">Redis</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please pass in Redis object.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">redis</span> <span class="o">=</span> <span class="n">redis_</span>

    <span class="k">def</span> <span class="nf">_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute key from prompt and llm_string&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_hash</span><span class="p">(</span><span class="n">prompt</span> <span class="o">+</span> <span class="n">llm_string</span><span class="p">)</span>

<div class="viewcode-block" id="RedisCache.lookup"><a class="viewcode-back" href="../../cache/langchain.cache.RedisCache.html#langchain.cache.RedisCache.lookup">[docs]</a>    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RETURN_VAL_TYPE</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Look up based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="n">generations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Read from a Redis HASH</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">redis</span><span class="o">.</span><span class="n">hgetall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_key</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">results</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">generations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Generation</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">generations</span> <span class="k">if</span> <span class="n">generations</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="RedisCache.update"><a class="viewcode-back" href="../../cache/langchain.cache.RedisCache.html#langchain.cache.RedisCache.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_val</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update cache based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">return_val</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">Generation</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;RedisCache only supports caching of normal LLM generations, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">ChatGeneration</span><span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;NOTE: Generation has not been cached. RedisCache does not&quot;</span>
                    <span class="s2">&quot; support caching ChatModel outputs.&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span>
        <span class="c1"># Write to a Redis HASH</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_key</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">redis</span><span class="o">.</span><span class="n">hset</span><span class="p">(</span>
            <span class="n">key</span><span class="p">,</span>
            <span class="n">mapping</span><span class="o">=</span><span class="p">{</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span> <span class="n">generation</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">generation</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">return_val</span><span class="p">)</span>
            <span class="p">},</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="RedisCache.clear"><a class="viewcode-back" href="../../cache/langchain.cache.RedisCache.html#langchain.cache.RedisCache.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear cache. If `asynchronous` is True, flush asynchronously.&quot;&quot;&quot;</span>
        <span class="n">asynchronous</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;asynchronous&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">redis</span><span class="o">.</span><span class="n">flushdb</span><span class="p">(</span><span class="n">asynchronous</span><span class="o">=</span><span class="n">asynchronous</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="RedisSemanticCache"><a class="viewcode-back" href="../../cache/langchain.cache.RedisSemanticCache.html#langchain.cache.RedisSemanticCache">[docs]</a><span class="k">class</span> <span class="nc">RedisSemanticCache</span><span class="p">(</span><span class="n">BaseCache</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache that uses Redis as a vector-store backend.&quot;&quot;&quot;</span>

    <span class="c1"># TODO - implement a TTL policy in Redis</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">redis_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">embedding</span><span class="p">:</span> <span class="n">Embeddings</span><span class="p">,</span> <span class="n">score_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize by passing in the `init` GPTCache func</span>

<span class="sd">        Args:</span>
<span class="sd">            redis_url (str): URL to connect to Redis.</span>
<span class="sd">            embedding (Embedding): Embedding provider for semantic encoding and search.</span>
<span class="sd">            score_threshold (float, 0.2):</span>

<span class="sd">        Example:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            import langchain</span>

<span class="sd">            from langchain.cache import RedisSemanticCache</span>
<span class="sd">            from langchain.embeddings import OpenAIEmbeddings</span>

<span class="sd">            langchain.llm_cache = RedisSemanticCache(</span>
<span class="sd">                redis_url=&quot;redis://localhost:6379&quot;,</span>
<span class="sd">                embedding=OpenAIEmbeddings()</span>
<span class="sd">            )</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">RedisVectorstore</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">redis_url</span> <span class="o">=</span> <span class="n">redis_url</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score_threshold</span> <span class="o">=</span> <span class="n">score_threshold</span>

    <span class="k">def</span> <span class="nf">_index_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">hashed_index</span> <span class="o">=</span> <span class="n">_hash</span><span class="p">(</span><span class="n">llm_string</span><span class="p">)</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;cache:</span><span class="si">{</span><span class="n">hashed_index</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">def</span> <span class="nf">_get_llm_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RedisVectorstore</span><span class="p">:</span>
        <span class="n">index_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_name</span><span class="p">(</span><span class="n">llm_string</span><span class="p">)</span>

        <span class="c1"># return vectorstore client for the specific llm string</span>
        <span class="k">if</span> <span class="n">index_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">[</span><span class="n">index_name</span><span class="p">]</span>

        <span class="c1"># create new vectorstore client for the specific llm string</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">[</span><span class="n">index_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">RedisVectorstore</span><span class="o">.</span><span class="n">from_existing_index</span><span class="p">(</span>
                <span class="n">embedding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">,</span>
                <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
                <span class="n">redis_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">redis_url</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="n">redis</span> <span class="o">=</span> <span class="n">RedisVectorstore</span><span class="p">(</span>
                <span class="n">embedding_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">embed_query</span><span class="p">,</span>
                <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
                <span class="n">redis_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">redis_url</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
            <span class="n">redis</span><span class="o">.</span><span class="n">_create_index</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">_embedding</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">[</span><span class="n">index_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">redis</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">[</span><span class="n">index_name</span><span class="p">]</span>

<div class="viewcode-block" id="RedisSemanticCache.clear"><a class="viewcode-back" href="../../cache/langchain.cache.RedisSemanticCache.html#langchain.cache.RedisSemanticCache.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear semantic cache for a given llm_string.&quot;&quot;&quot;</span>
        <span class="n">index_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_name</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;llm_string&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">index_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">[</span><span class="n">index_name</span><span class="p">]</span><span class="o">.</span><span class="n">drop_index</span><span class="p">(</span>
                <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span> <span class="n">delete_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">redis_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">redis_url</span>
            <span class="p">)</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache_dict</span><span class="p">[</span><span class="n">index_name</span><span class="p">]</span></div>

<div class="viewcode-block" id="RedisSemanticCache.lookup"><a class="viewcode-back" href="../../cache/langchain.cache.RedisSemanticCache.html#langchain.cache.RedisSemanticCache.lookup">[docs]</a>    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RETURN_VAL_TYPE</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Look up based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="n">llm_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_llm_cache</span><span class="p">(</span><span class="n">llm_string</span><span class="p">)</span>
        <span class="n">generations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Read from a Hash</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">llm_cache</span><span class="o">.</span><span class="n">similarity_search_limit_score</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">score_threshold</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">score_threshold</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">results</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;return_val&quot;</span><span class="p">]:</span>
                    <span class="n">generations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Generation</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">generations</span> <span class="k">if</span> <span class="n">generations</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="RedisSemanticCache.update"><a class="viewcode-back" href="../../cache/langchain.cache.RedisSemanticCache.html#langchain.cache.RedisSemanticCache.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_val</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update cache based on prompt and llm_string.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">return_val</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">Generation</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;RedisSemanticCache only supports caching of &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;normal LLM generations, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">ChatGeneration</span><span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;NOTE: Generation has not been cached. RedisSentimentCache does not&quot;</span>
                    <span class="s2">&quot; support caching ChatModel outputs.&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span>
        <span class="n">llm_cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_llm_cache</span><span class="p">(</span><span class="n">llm_string</span><span class="p">)</span>
        <span class="c1"># Write to vectorstore</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;llm_string&quot;</span><span class="p">:</span> <span class="n">llm_string</span><span class="p">,</span>
            <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
            <span class="s2">&quot;return_val&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">generation</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">generation</span> <span class="ow">in</span> <span class="n">return_val</span><span class="p">],</span>
        <span class="p">}</span>
        <span class="n">llm_cache</span><span class="o">.</span><span class="n">add_texts</span><span class="p">(</span><span class="n">texts</span><span class="o">=</span><span class="p">[</span><span class="n">prompt</span><span class="p">],</span> <span class="n">metadatas</span><span class="o">=</span><span class="p">[</span><span class="n">metadata</span><span class="p">])</span></div></div>


<div class="viewcode-block" id="GPTCache"><a class="viewcode-back" href="../../cache/langchain.cache.GPTCache.html#langchain.cache.GPTCache">[docs]</a><span class="k">class</span> <span class="nc">GPTCache</span><span class="p">(</span><span class="n">BaseCache</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache that uses GPTCache as a backend.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">init_func</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span> <span class="kc">None</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize by passing in init function (default: `None`).</span>

<span class="sd">        Args:</span>
<span class="sd">            init_func (Optional[Callable[[Any], None]]): init `GPTCache` function</span>
<span class="sd">            (default: `None`)</span>

<span class="sd">        Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Initialize GPTCache with a custom init function</span>
<span class="sd">            import gptcache</span>
<span class="sd">            from gptcache.processor.pre import get_prompt</span>
<span class="sd">            from gptcache.manager.factory import get_data_manager</span>

<span class="sd">            # Avoid multiple caches using the same file,</span>
<span class="sd">            causing different llm model caches to affect each other</span>

<span class="sd">            def init_gptcache(cache_obj: gptcache.Cache, llm str):</span>
<span class="sd">                cache_obj.init(</span>
<span class="sd">                    pre_embedding_func=get_prompt,</span>
<span class="sd">                    data_manager=manager_factory(</span>
<span class="sd">                        manager=&quot;map&quot;,</span>
<span class="sd">                        data_dir=f&quot;map_cache_{llm}&quot;</span>
<span class="sd">                    ),</span>
<span class="sd">                )</span>

<span class="sd">            langchain.llm_cache = GPTCache(init_gptcache)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">gptcache</span>  <span class="c1"># noqa: F401</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Could not import gptcache python package. &quot;</span>
                <span class="s2">&quot;Please install it with `pip install gptcache`.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_gptcache_func</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span> <span class="kc">None</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">init_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gptcache_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">_new_gptcache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;New gptcache object&quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">gptcache</span> <span class="kn">import</span> <span class="n">Cache</span>
        <span class="kn">from</span> <span class="nn">gptcache.manager.factory</span> <span class="kn">import</span> <span class="n">get_data_manager</span>
        <span class="kn">from</span> <span class="nn">gptcache.processor.pre</span> <span class="kn">import</span> <span class="n">get_prompt</span>

        <span class="n">_gptcache</span> <span class="o">=</span> <span class="n">Cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_gptcache_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_gptcache_func</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_gptcache_func</span><span class="p">(</span><span class="n">_gptcache</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">)</span>  <span class="c1"># type: ignore[call-arg]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_gptcache_func</span><span class="p">(</span><span class="n">_gptcache</span><span class="p">)</span>  <span class="c1"># type: ignore[call-arg]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_gptcache</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
                <span class="n">pre_embedding_func</span><span class="o">=</span><span class="n">get_prompt</span><span class="p">,</span>
                <span class="n">data_manager</span><span class="o">=</span><span class="n">get_data_manager</span><span class="p">(</span><span class="n">data_path</span><span class="o">=</span><span class="n">llm_string</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gptcache_dict</span><span class="p">[</span><span class="n">llm_string</span><span class="p">]</span> <span class="o">=</span> <span class="n">_gptcache</span>
        <span class="k">return</span> <span class="n">_gptcache</span>

    <span class="k">def</span> <span class="nf">_get_gptcache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get a cache object.</span>

<span class="sd">        When the corresponding llm model cache does not exist, it will be created.&quot;&quot;&quot;</span>
        <span class="n">_gptcache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gptcache_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">llm_string</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_gptcache</span><span class="p">:</span>
            <span class="n">_gptcache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_gptcache</span><span class="p">(</span><span class="n">llm_string</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_gptcache</span>

<div class="viewcode-block" id="GPTCache.lookup"><a class="viewcode-back" href="../../cache/langchain.cache.GPTCache.html#langchain.cache.GPTCache.lookup">[docs]</a>    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RETURN_VAL_TYPE</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Look up the cache data.</span>
<span class="sd">        First, retrieve the corresponding cache object using the `llm_string` parameter,</span>
<span class="sd">        and then retrieve the data from the cache based on the `prompt`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">gptcache.adapter.api</span> <span class="kn">import</span> <span class="n">get</span>

        <span class="n">_gptcache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gptcache_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">llm_string</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_gptcache</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">get</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">cache_obj</span><span class="o">=</span><span class="n">_gptcache</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">res</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="n">Generation</span><span class="p">(</span><span class="o">**</span><span class="n">generation_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">generation_dict</span> <span class="ow">in</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="GPTCache.update"><a class="viewcode-back" href="../../cache/langchain.cache.GPTCache.html#langchain.cache.GPTCache.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_val</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update cache.</span>
<span class="sd">        First, retrieve the corresponding cache object using the `llm_string` parameter,</span>
<span class="sd">        and then store the `prompt` and `return_val` in the cache object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">return_val</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">Generation</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;GPTCache only supports caching of normal LLM generations, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="kn">from</span> <span class="nn">gptcache.adapter.api</span> <span class="kn">import</span> <span class="n">put</span>

        <span class="n">_gptcache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_gptcache</span><span class="p">(</span><span class="n">llm_string</span><span class="p">)</span>
        <span class="n">handled_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">([</span><span class="n">generation</span><span class="o">.</span><span class="n">dict</span><span class="p">()</span> <span class="k">for</span> <span class="n">generation</span> <span class="ow">in</span> <span class="n">return_val</span><span class="p">])</span>
        <span class="n">put</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">handled_data</span><span class="p">,</span> <span class="n">cache_obj</span><span class="o">=</span><span class="n">_gptcache</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="GPTCache.clear"><a class="viewcode-back" href="../../cache/langchain.cache.GPTCache.html#langchain.cache.GPTCache.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear cache.&quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">gptcache</span> <span class="kn">import</span> <span class="n">Cache</span>

        <span class="k">for</span> <span class="n">gptcache_instance</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">gptcache_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">gptcache_instance</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Cache</span><span class="p">,</span> <span class="n">gptcache_instance</span><span class="p">)</span>
            <span class="n">gptcache_instance</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gptcache_dict</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span></div></div>


<span class="k">def</span> <span class="nf">_ensure_cache_exists</span><span class="p">(</span><span class="n">cache_client</span><span class="p">:</span> <span class="n">momento</span><span class="o">.</span><span class="n">CacheClient</span><span class="p">,</span> <span class="n">cache_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create cache if it doesn&#39;t exist.</span>

<span class="sd">    Raises:</span>
<span class="sd">        SdkException: Momento service or network error</span>
<span class="sd">        Exception: Unexpected response</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">momento.responses</span> <span class="kn">import</span> <span class="n">CreateCache</span>

    <span class="n">create_cache_response</span> <span class="o">=</span> <span class="n">cache_client</span><span class="o">.</span><span class="n">create_cache</span><span class="p">(</span><span class="n">cache_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_cache_response</span><span class="p">,</span> <span class="n">CreateCache</span><span class="o">.</span><span class="n">Success</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">create_cache_response</span><span class="p">,</span> <span class="n">CreateCache</span><span class="o">.</span><span class="n">CacheAlreadyExists</span>
    <span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_cache_response</span><span class="p">,</span> <span class="n">CreateCache</span><span class="o">.</span><span class="n">Error</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">create_cache_response</span><span class="o">.</span><span class="n">inner_exception</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected response cache creation: </span><span class="si">{</span><span class="n">create_cache_response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_validate_ttl</span><span class="p">(</span><span class="n">ttl</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">timedelta</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">ttl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ttl</span> <span class="o">&lt;=</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ttl must be positive but was </span><span class="si">{</span><span class="n">ttl</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="MomentoCache"><a class="viewcode-back" href="../../cache/langchain.cache.MomentoCache.html#langchain.cache.MomentoCache">[docs]</a><span class="k">class</span> <span class="nc">MomentoCache</span><span class="p">(</span><span class="n">BaseCache</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache that uses Momento as a backend. See https://gomomento.com/&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cache_client</span><span class="p">:</span> <span class="n">momento</span><span class="o">.</span><span class="n">CacheClient</span><span class="p">,</span>
        <span class="n">cache_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">ttl</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">timedelta</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ensure_cache_exists</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Instantiate a prompt cache using Momento as a backend.</span>

<span class="sd">        Note: to instantiate the cache client passed to MomentoCache,</span>
<span class="sd">        you must have a Momento account. See https://gomomento.com/.</span>

<span class="sd">        Args:</span>
<span class="sd">            cache_client (CacheClient): The Momento cache client.</span>
<span class="sd">            cache_name (str): The name of the cache to use to store the data.</span>
<span class="sd">            ttl (Optional[timedelta], optional): The time to live for the cache items.</span>
<span class="sd">                Defaults to None, ie use the client default TTL.</span>
<span class="sd">            ensure_cache_exists (bool, optional): Create the cache if it doesn&#39;t</span>
<span class="sd">                exist. Defaults to True.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ImportError: Momento python package is not installed.</span>
<span class="sd">            TypeError: cache_client is not of type momento.CacheClientObject</span>
<span class="sd">            ValueError: ttl is non-null and non-negative</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">momento</span> <span class="kn">import</span> <span class="n">CacheClient</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Could not import momento python package. &quot;</span>
                <span class="s2">&quot;Please install it with `pip install momento`.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cache_client</span><span class="p">,</span> <span class="n">CacheClient</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cache_client must be a momento.CacheClient object.&quot;</span><span class="p">)</span>
        <span class="n">_validate_ttl</span><span class="p">(</span><span class="n">ttl</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ensure_cache_exists</span><span class="p">:</span>
            <span class="n">_ensure_cache_exists</span><span class="p">(</span><span class="n">cache_client</span><span class="p">,</span> <span class="n">cache_name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cache_client</span> <span class="o">=</span> <span class="n">cache_client</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_name</span> <span class="o">=</span> <span class="n">cache_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ttl</span> <span class="o">=</span> <span class="n">ttl</span>

<div class="viewcode-block" id="MomentoCache.from_client_params"><a class="viewcode-back" href="../../cache/langchain.cache.MomentoCache.html#langchain.cache.MomentoCache.from_client_params">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_client_params</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">cache_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">ttl</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">configuration</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">momento</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">Configuration</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">auth_token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MomentoCache</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct cache from CacheClient parameters.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">momento</span> <span class="kn">import</span> <span class="n">CacheClient</span><span class="p">,</span> <span class="n">Configurations</span><span class="p">,</span> <span class="n">CredentialProvider</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Could not import momento python package. &quot;</span>
                <span class="s2">&quot;Please install it with `pip install momento`.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">configuration</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">configuration</span> <span class="o">=</span> <span class="n">Configurations</span><span class="o">.</span><span class="n">Laptop</span><span class="o">.</span><span class="n">v1</span><span class="p">()</span>
        <span class="n">auth_token</span> <span class="o">=</span> <span class="n">auth_token</span> <span class="ow">or</span> <span class="n">get_from_env</span><span class="p">(</span><span class="s2">&quot;auth_token&quot;</span><span class="p">,</span> <span class="s2">&quot;MOMENTO_AUTH_TOKEN&quot;</span><span class="p">)</span>
        <span class="n">credentials</span> <span class="o">=</span> <span class="n">CredentialProvider</span><span class="o">.</span><span class="n">from_string</span><span class="p">(</span><span class="n">auth_token</span><span class="p">)</span>
        <span class="n">cache_client</span> <span class="o">=</span> <span class="n">CacheClient</span><span class="p">(</span><span class="n">configuration</span><span class="p">,</span> <span class="n">credentials</span><span class="p">,</span> <span class="n">default_ttl</span><span class="o">=</span><span class="n">ttl</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">cache_client</span><span class="p">,</span> <span class="n">cache_name</span><span class="p">,</span> <span class="n">ttl</span><span class="o">=</span><span class="n">ttl</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute cache key from prompt and associated model and settings.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (str): The prompt run through the language model.</span>
<span class="sd">            llm_string (str): The language model version and settings.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The cache key.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_hash</span><span class="p">(</span><span class="n">prompt</span> <span class="o">+</span> <span class="n">llm_string</span><span class="p">)</span>

<div class="viewcode-block" id="MomentoCache.lookup"><a class="viewcode-back" href="../../cache/langchain.cache.MomentoCache.html#langchain.cache.MomentoCache.lookup">[docs]</a>    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RETURN_VAL_TYPE</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Lookup llm generations in cache by prompt and associated model and settings.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (str): The prompt run through the language model.</span>
<span class="sd">            llm_string (str): The language model version and settings.</span>

<span class="sd">        Raises:</span>
<span class="sd">            SdkException: Momento service or network error</span>

<span class="sd">        Returns:</span>
<span class="sd">            Optional[RETURN_VAL_TYPE]: A list of language model generations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">momento.responses</span> <span class="kn">import</span> <span class="n">CacheGet</span>

        <span class="n">generations</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">get_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_client</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__key</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">get_response</span><span class="p">,</span> <span class="n">CacheGet</span><span class="o">.</span><span class="n">Hit</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">get_response</span><span class="o">.</span><span class="n">value_string</span>
            <span class="n">generations</span> <span class="o">=</span> <span class="n">_load_generations_from_json</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">get_response</span><span class="p">,</span> <span class="n">CacheGet</span><span class="o">.</span><span class="n">Miss</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">get_response</span><span class="p">,</span> <span class="n">CacheGet</span><span class="o">.</span><span class="n">Error</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">get_response</span><span class="o">.</span><span class="n">inner_exception</span>
        <span class="k">return</span> <span class="n">generations</span> <span class="k">if</span> <span class="n">generations</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="MomentoCache.update"><a class="viewcode-back" href="../../cache/langchain.cache.MomentoCache.html#langchain.cache.MomentoCache.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">return_val</span><span class="p">:</span> <span class="n">RETURN_VAL_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Store llm generations in cache.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (str): The prompt run through the language model.</span>
<span class="sd">            llm_string (str): The language model string.</span>
<span class="sd">            return_val (RETURN_VAL_TYPE): A list of language model generations.</span>

<span class="sd">        Raises:</span>
<span class="sd">            SdkException: Momento service or network error</span>
<span class="sd">            Exception: Unexpected response</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">return_val</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">Generation</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Momento only supports caching of normal LLM generations, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__key</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm_string</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">_dump_generations_to_json</span><span class="p">(</span><span class="n">return_val</span><span class="p">)</span>
        <span class="n">set_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_client</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_name</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ttl</span><span class="p">)</span>
        <span class="kn">from</span> <span class="nn">momento.responses</span> <span class="kn">import</span> <span class="n">CacheSet</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">set_response</span><span class="p">,</span> <span class="n">CacheSet</span><span class="o">.</span><span class="n">Success</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">set_response</span><span class="p">,</span> <span class="n">CacheSet</span><span class="o">.</span><span class="n">Error</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">set_response</span><span class="o">.</span><span class="n">inner_exception</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected response: </span><span class="si">{</span><span class="n">set_response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="MomentoCache.clear"><a class="viewcode-back" href="../../cache/langchain.cache.MomentoCache.html#langchain.cache.MomentoCache.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clear the cache.</span>

<span class="sd">        Raises:</span>
<span class="sd">            SdkException: Momento service or network error</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">momento.responses</span> <span class="kn">import</span> <span class="n">CacheFlush</span>

        <span class="n">flush_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_client</span><span class="o">.</span><span class="n">flush_cache</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">flush_response</span><span class="p">,</span> <span class="n">CacheFlush</span><span class="o">.</span><span class="n">Success</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">flush_response</span><span class="p">,</span> <span class="n">CacheFlush</span><span class="o">.</span><span class="n">Error</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">flush_response</span><span class="o">.</span><span class="n">inner_exception</span></div></div>
</pre></div>

      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2023, Harrison Chase.
          Last updated on Jul 29, 2023.
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>
<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">Â¶</a>');
	});
});

</script>
    
</body>
</html>